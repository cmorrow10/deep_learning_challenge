Deep Learning Challenge Report
The nonprofit foundation Alphabet Soup wants a tool that can help it select the applicants for funding with the best chance of success in their ventures. With machine learning and neural networks, from the charity_data.csv dataset, the goal is to create a binary classifier that can predict whether applicants will be successful if funded by Alphabet Soup.

AlphbetSoupCharity_Optimization was the targeted goal model.

The target variable for the model is ‘IS_SUCCESSFUL’ and is trying to predict results based on the input features. The model was able to attempt to classify whether a charity organization will be successful (1) or not (0) in obtaining funding.

The features for the model are all the columns in the DataFrame ‘application_df’ after preprocessing. Specifically, they are the columns obtained after converting categorical data to numeric using ‘pd.get_dummies’.
The variable 'EIN' is removed from the input data as it does not contribute to predicting the target variable ('IS_SUCCESSFUL') and did not contain meaningful information for the model.

The number of neurons, layers, and activation functions in the neural network model were:
-	Neurons: First hidden layer: 10 neurons, Second hidden layer: 8 neurons, Third hidden layer: 6 neurons, and Output layer: 1 neuron. 
-	Layers: The model has a total of 4 layers: 3 hidden layers and 1 output layer. 
-	Activation Functions: First hidden layer: ReLU activation function, Second hidden layer: Sigmoid activation function, Third hidden layer: Sigmoid activation function, and Output layer: Sigmoid activation function.

The target predictive accuracy was to reach higher than 75%. The goal was reached by an Accuracy of 0.7537026405334473. 
Steps taken in attempts to increase model performance were: Adding a third hidden layer to increase complexity and capacity to learn intricate patterns and representations from the input data. Updating neurons for adjusting the weights and biases of neurons in a neural network during the training phase. Updating activation functions by introducing non- linearity to the model. And by binning the ‘NAME’ column to reduce the dimensionality of the feature.

Overall, applicants will be 75.37% successful if funded by Alphabet Soup. The accuracy indicates that the model correctly predicted the target variable ('IS_SUCCESSFUL').  The loss value of 0.4891 indicates the discrepancy between the model's predictions and the actual targets, with lower values indicating better performance.
By adding additional architectures such as adding more hidden layers or using different types of layers, this could improve the model's performance.
